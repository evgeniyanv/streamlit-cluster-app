import re
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer



# --- –û—á–∏—Å—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: —Ç–æ–ª—å–∫–æ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ ---
def clean_dataset(df):
    return df.dropna().copy()

def remove_outliers_iqr(df: pd.DataFrame, numeric_cols: list, factor: float = 1.5) -> pd.DataFrame:
    """
    –£–¥–∞–ª—è–µ—Ç –≤—ã–±—Ä–æ—Å—ã –ø–æ IQR –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    factor=1.5 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∞–≤–∏–ª—É –¢—å—é–∫–∏.
    """
    df_clean = df.copy()
    for col in numeric_cols:
        if col in df_clean.columns and pd.api.types.is_numeric_dtype(df_clean[col]):
            Q1 = df_clean[col].quantile(0.25)
            Q3 = df_clean[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - factor * IQR
            upper = Q3 + factor * IQR
            df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]
    return df_clean


# --- –ü–∞—Ä—Å–∏–Ω–≥ ST_PROD ---

def add_standard_features_v2(df: pd.DataFrame, col: str = "ST_PROD") -> pd.DataFrame:
    """
    –†–∞–∑–±–∏—Ä–∞–µ—Ç —Å—Ç–æ–ª–±–µ—Ü —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –Ω–∞:
      - system: —Å–∏—Å—Ç–µ–º–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ (–ì–û–°–¢, EN, ASTM, –°–¢–û, ISO, DIN, –¢–£, ...)
      - code: –∫–æ–¥ –±–µ–∑ –≥–æ–¥–∞ –∏ –ø–æ–º–µ—Ç–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, '10025-3', '27772', '00186217-340')
      - year: –≥–æ–¥ –≤—ã–ø—É—Å–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ (–±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞–ª–∏–¥–Ω—ã–π –≥–æ–¥ 1900‚Äì2099), —Ç–∏–ø Int64 (nullable)
    """
    if col not in df.columns:
        return df

    sys_list, code_list, year_list = [], [], []

    for raw in df[col].fillna(""):
        text = str(raw).strip()
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏—Ä–µ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        t = (text.replace("‚Äì", "-").replace("‚Äî", "-")
                    .replace("\u00A0", " "))  # NBSP -> space

        # 1) system ‚Äî –ø–µ—Ä–≤–æ–µ –±—É–∫–≤–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –≤ –Ω–∞—á–∞–ª–µ, –∏–Ω–∞—á–µ –∏—â–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –≤–Ω—É—Ç—Ä–∏
        m_sys = re.match(r"^\s*([A-Za-z–ê-–Ø–∞-—è]+)", t)
        system = m_sys.group(1) if m_sys else None
        if not system:
            m_known = re.search(r"\b(–ì–û–°–¢|EN|ISO|DIN|ASTM|–°–¢–û|–¢–£)\b", t, flags=re.IGNORECASE)
            system = m_known.group(1) if m_known else "UNKNOWN"
        system = system.upper() if re.match(r"^[A-Za-z]+$", system) else system

        # 2) year ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞–ª–∏–¥–Ω—ã–π –≥–æ–¥ (1900‚Äì2099)
        year_matches = list(re.finditer(r"(?<!\d)(19|20)\d{2}(?!\d)", t))
        if year_matches:
            year = int(year_matches[-1].group(0))
            year_pos = year_matches[-1].start()
        else:
            year = pd.NA
            year_pos = len(t)

        # 3) code ‚Äî —á–∞—Å—Ç—å –º–µ–∂–¥—É —Å–∏—Å—Ç–µ–º–æ–π –∏ –≥–æ–¥–æ–º
        start = m_sys.end() if m_sys else 0
        candidate = t[start:year_pos]

        # —É–¥–∞–ª—è–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –º–∞—Ä–∫–µ—Ä–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ ¬´–∫–æ–¥–∞¬ª
        candidate = re.sub(r"\b(–∏–∑–º|–∏–∑–º–µ–Ω|–ø–æ–ø—Ä|amend|amd)\b.*$", "", candidate, flags=re.IGNORECASE)

        # —á–∏—Å—Ç–∏–º —Å–∏–º–≤–æ–ª—ã —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Å —Ö–≤–æ—Å—Ç–∞/–Ω–∞—á–∞–ª–∞
        candidate = candidate.strip(" :,-;/\t")
        candidate = re.sub(r"[:\s-]+$", "", candidate)
        candidate = re.sub(r"\s+", " ", candidate)

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        sys_list.append(system if system else "UNKNOWN")
        code_list.append(candidate if candidate else "UNKNOWN")
        year_list.append(year)

    out = df.copy()
    out["system"] = sys_list
    out["code"] = code_list
    out["year"] = pd.Series(year_list, dtype="Int64")
    return out




# --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫–æ–ª–æ–Ω–æ–∫ ---
def detect_column_types(df):
    numeric_cols, categorical_cols = [], []

    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            numeric_cols.append(col)
        else:
            # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª—É
            converted = pd.to_numeric(df[col], errors='coerce')
            if converted.notna().sum() > 0 and converted.isna().sum() == 0:
                numeric_cols.append(col)
                df[col] = converted  # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ
            else:
                categorical_cols.append(col)

    return df, numeric_cols, categorical_cols


# --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---
# def prepare_features_with_standard(df, selected_cols, target_col=None):
#     df = df.copy()

#     # –æ—Ç–¥–µ–ª—è–µ–º —Ç–∞—Ä–≥–µ—Ç
#     y = None
#     if target_col and target_col in df.columns:
#         y = df[target_col].values
#         df = df.drop(columns=[target_col])

#     # —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
#     df = df[selected_cols]

#     # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
#     filled_cols = []
#     for col in df.columns:
#         if df[col].isna().any():
#             filled_cols.append(col)
#             if pd.api.types.is_numeric_dtype(df[col]):
#                 df[col] = df[col].fillna(0)
#             else:
#                 df[col] = df[col].fillna("UNKNOWN")

#     # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
#     df, numeric_cols, categorical_cols = detect_column_types(df)

#     transformers = []

#     # —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Üí StandardScaler
#     if numeric_cols:
#         transformers.append(('num', StandardScaler(), numeric_cols))

#     # system ‚Üí OneHot
#     if 'system' in df.columns:
#         transformers.append(('system', OneHotEncoder(handle_unknown='ignore', sparse_output=True), ['system']))

#     # code ‚Üí TF-IDF
#     if 'code' in df.columns:
#         transformers.append(('code', TfidfVectorizer(analyzer='char', ngram_range=(3, 4)), 'code'))

#     # year ‚Üí StandardScaler
#     if 'year' in df.columns:
#         transformers.append(('year', StandardScaler(), ['year']))

#     # has_updates ‚Üí passthrough
#     if 'has_updates' in df.columns:
#         transformers.append(('has_updates', 'passthrough', ['has_updates']))

#     # MARKA ‚Üí TF-IDF
#     if 'MARKA' in df.columns:
#         transformers.append(('marka', TfidfVectorizer(analyzer='char', ngram_range=(3, 4)), 'MARKA'))

#     # –ø—Ä–æ—á–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ ‚Üí OneHot
#     other_cats = [c for c in categorical_cols if c not in ['system', 'code', 'year', 'has_updates', 'MARKA']]
#     if other_cats:
#         transformers.append(('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), other_cats))

#     preprocessor = ColumnTransformer(transformers=transformers, remainder='drop', sparse_threshold=0)

#     X = preprocessor.fit_transform(df)
#     return X, y, filled_cols

def prepare_features_with_standard(df, selected_cols, target_col=None):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:
    - –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Üí StandardScaler
    - –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:
        * –µ—Å–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ‚â§10 ‚Üí OneHotEncoder
        * –µ—Å–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π >10 ‚Üí LabelEncoder
    - –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ('code', 'MARKA') ‚Üí TF-IDF
    """

    df = df.copy()

    # --- –û—Ç–¥–µ–ª—è–µ–º —Ç–∞—Ä–≥–µ—Ç
    y = None
    if target_col and target_col in df.columns:
        y = df[target_col].values
        df = df.drop(columns=[target_col])

    df = df[selected_cols]

    # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    filled_cols = []
    for col in df.columns:
        if df[col].isna().any():
            filled_cols.append(col)
            if pd.api.types.is_numeric_dtype(df[col]):
                df[col] = df[col].fillna(0)
            else:
                df[col] = df[col].fillna("UNKNOWN")

    # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df, numeric_cols, categorical_cols = detect_column_types(df)

    transformers = []
    log_messages = []  # –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ

    # --- –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Üí StandardScaler
    if numeric_cols:
        transformers.append(("num", StandardScaler(), numeric_cols))
        log_messages.append(f"üîπ –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(numeric_cols)}): {', '.join(numeric_cols)}")

    # --- –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Üí OHE –∏–ª–∏ LabelEncoder
    le_encoded = []
    for col in categorical_cols:
        # ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–∞—è TF-IDF –æ–±—Ä–∞–±–æ—Ç–∫–∞
        if col in ["code", "MARKA"]:
            continue

        n_unique = df[col].nunique()
        if n_unique <= 10:
            transformers.append((f"ohe_{col}", OneHotEncoder(handle_unknown="ignore"), [col]))
            log_messages.append(f"üü¢ {col} (OHE, {n_unique} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö)")
        else:
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))
            transformers.append((f"le_{col}", "passthrough", [col]))
            le_encoded.append(col)
            log_messages.append(f"üü† {col} (LabelEncoder, {n_unique} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö)")


    # --- TF-IDF –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   
    for text_col in ["code", "MARKA"]:
        if text_col in df.columns:
            df[text_col] = df[text_col].astype(str)

    if "code" in df.columns:
        transformers.append(("code_tfidf", TfidfVectorizer(analyzer="char", ngram_range=(3, 4)), "code"))
        log_messages.append("üî§ 'code' ‚Üí TF-IDF")

    if "MARKA" in df.columns:
        transformers.append(("marka_tfidf", TfidfVectorizer(analyzer="char", ngram_range=(3, 4)), "MARKA"))
        log_messages.append("üî§ 'MARKA' ‚Üí TF-IDF")

    # --- ColumnTransformer
    preprocessor = ColumnTransformer(transformers=transformers, remainder="drop", sparse_threshold=0)
    X = preprocessor.fit_transform(df)
    
    # --- –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    try:
        feature_names = preprocessor.get_feature_names_out()
    except Exception:
        feature_names = [f"feature_{i}" for i in range(X.shape[1])]

    return X, y, filled_cols, log_messages, feature_names

